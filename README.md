# Cyber Assessment Reviewer - Modular Edition

A modular, AI-powered cybersecurity control analysis system that helps organizations review and assess their cybersecurity controls against various compliance frameworks.

## ğŸš€ Features

- **AI-Powered Analysis**: Uses Mistral 7B or other LLMs for intelligent control assessment
- **Multiple Backends**: Supports both Ollama (recommended) and Transformers
- **Framework Support**: NIST, ISO 27001, SOC 2, CIS Controls, PCI DSS
- **File Processing**: Supports PDF, DOCX, XLSX, PPTX evidence files
- **Risk Assessment**: Comprehensive risk scoring and compliance metrics
- **Excel Reports**: Detailed analysis reports in Excel format
- **Modular Architecture**: Clean, maintainable code structure

## ğŸ“ Project Structure

```
cyber-assessment-reviewer/
â”œâ”€â”€ app.py                 # Main application entry point
â”œâ”€â”€ config.py             # Configuration management
â”œâ”€â”€ models.py             # Data models and classes
â”œâ”€â”€ utils.py              # Utility functions and helpers
â”œâ”€â”€ file_processors.py    # File processing logic
â”œâ”€â”€ ai_backend.py         # AI/LLM backend management
â”œâ”€â”€ routes.py             # Flask routes and web logic
â”œâ”€â”€ templates.py          # HTML template generation
â”œâ”€â”€ requirements.txt      # Full dependencies
â”œâ”€â”€ requirements-core.txt # Core dependencies only
â””â”€â”€ README.md            # This file
```

## ğŸ› ï¸ Installation

### Option 1: With Ollama (Recommended)

1. **Install Ollama** (easier setup, better performance):
   ```bash
   # Visit https://ollama.com and install Ollama
   # Then pull the required model:
   ollama pull mistral:7b-instruct
   ```

2. **Install core dependencies**:
   ```bash
   pip install -r requirements-core.txt
   ```

### Option 2: With Transformers (No Ollama)

1. **Install all dependencies** (includes PyTorch and Transformers):
   ```bash
   pip install -r requirements.txt
   ```

## ğŸš€ Usage

### Starting the Application

```bash
python app.py
```

The application will:
- Check and install missing dependencies automatically
- Initialize the AI backend (Ollama or Transformers)
- Start the web server on http://localhost:5000

### Using the Web Interface

1. **Select Framework**: Choose your compliance framework (NIST, ISO 27001, etc.)
2. **Upload Assessment**: Upload your control assessment file (Excel format)
3. **Upload Evidence**: Upload supporting evidence files (PDF, DOCX, XLSX, PPTX)
4. **Analyze**: Click "Analyze Assessment" to start the AI analysis
5. **Download Report**: Get detailed Excel report with findings and recommendations

## ğŸ“Š Supported File Formats

### Assessment Files
- **Excel (.xlsx)**: Control matrices with columns for control ID, name, requirements, answers, status

### Evidence Files
- **PDF (.pdf)**: Policy documents, procedures, screenshots
- **Word (.docx)**: Documentation, procedures, reports
- **PowerPoint (.pptx)**: Presentations, training materials
- **Excel (.xlsx)**: Additional data, logs, configurations

## ğŸš€ Quick Start

**For development (with production WSGI server):**
```bash
python app.py
```

**For production deployment:**
```bash
python run_production.py
```

**For the original monolithic version:**
```bash
python cyber-assessment-reviewerv37.py
```

## ğŸ­ Production WSGI Server

The application now uses **production-ready WSGI servers** instead of Flask's development server:

- **Waitress** (Windows/Cross-platform) - Automatically installed and used
- **Gunicorn** (Linux/Unix) - Used on Unix-like systems
- **Automatic detection** - Chooses the best server for your platform

### Benefits:
- âœ… **No more development server warnings**
- âœ… **Better performance and stability**
- âœ… **Production-ready out of the box**
- âœ… **Automatic installation if missing**

### Configuration:
```bash
# Environment variables for WSGI server tuning
export WSGI_WORKERS=4        # Number of worker processes (Gunicorn)
export WSGI_THREADS=4        # Number of threads per worker
export WSGI_TIMEOUT=120      # Request timeout in seconds
export USE_PRODUCTION_SERVER=true  # Force production server (default: true)
```

## ğŸ³ Docker Deployment

The application is fully containerized with Docker for easy deployment and scaling.

### ğŸš€ Quick Start with Docker

**1. Build the Docker images:**
```bash
chmod +x docker-build.sh
./docker-build.sh
```

**2. Deploy with Ollama (Recommended):**
```bash
chmod +x docker-deploy.sh
./docker-deploy.sh --mode ollama
```

**3. Deploy with Transformers (Standalone):**
```bash
./docker-deploy.sh --mode transformers
```

### ğŸ“¦ Docker Images

The project provides two optimized Docker images:

- **`cyber-assessment-reviewer:latest`** - Production image with Ollama support (smaller, faster)
- **`cyber-assessment-reviewer:transformers`** - Full image with Transformers support (larger, self-contained)

### ğŸ”§ Docker Compose Configurations

**Standard deployment (with Ollama):**
```bash
docker-compose up -d
```

**Transformers-only deployment:**
```bash
docker-compose -f docker-compose.transformers.yml up -d
```

### ğŸŒ Services

| Service | Port | Description |
|---------|------|-------------|
| **cyber-assessment-reviewer** | 5000 | Main application |
| **ollama** | 11434 | AI model server (Ollama mode only) |

### ğŸ“ Persistent Data

Docker volumes are automatically created for:
- `./data/uploads` - Uploaded assessment and evidence files
- `./data/sessions` - User sessions and analysis results
- `./data/logs` - Application logs
- `./data/models` - Cached AI models
- `./data/ollama` - Ollama model storage (Ollama mode)
- `./data/transformers_cache` - Transformers model cache (Transformers mode)

### âš™ï¸ Environment Configuration

Copy and customize the environment file:
```bash
cp .env.example .env
# Edit .env with your configuration
```

**Key environment variables:**
```bash
# Security
SECRET_KEY=your-super-secret-key-change-this

# AI Backend
USE_OLLAMA=true                    # true for Ollama, false for Transformers
OLLAMA_BASE_URL=http://ollama:11434
DEFAULT_MODEL_NAME=mistral:7b-instruct

# Performance
WSGI_WORKERS=4
WSGI_THREADS=4
MAX_CONTROLS_DEFAULT=20

# Resources
MAX_CONTENT_LENGTH=52428800        # 50MB file upload limit
```

### ğŸ” Health Checks

Both services include comprehensive health checks:
- **Application**: `http://localhost:5000/system_status`
- **Ollama**: `http://localhost:11434/api/tags`

### ğŸ“Š Resource Requirements

**Minimum requirements:**
- **RAM**: 4GB (Ollama mode), 8GB (Transformers mode)
- **Storage**: 10GB for models and data
- **CPU**: 2 cores minimum, 4+ recommended

**Recommended for production:**
- **RAM**: 8GB (Ollama), 16GB (Transformers)
- **Storage**: 50GB SSD
- **CPU**: 4+ cores
- **GPU**: Optional but recommended for Transformers mode

### ğŸ› Docker Troubleshooting

**Check service status:**
```bash
docker-compose ps
docker-compose logs -f
```

**Restart services:**
```bash
docker-compose restart
```

**Clean rebuild:**
```bash
docker-compose down
docker system prune -f
./docker-build.sh
./docker-deploy.sh
```

**Check Ollama models:**
```bash
docker-compose exec ollama ollama list
```

**Monitor resource usage:**
```bash
docker stats
```

### ğŸ”’ Production Security

For production deployments:

1. **Set a strong SECRET_KEY**:
   ```bash
   export SECRET_KEY=$(openssl rand -hex 32)
   ```

2. **Use HTTPS with reverse proxy** (nginx/traefik)

3. **Limit file upload sizes** and types

4. **Regular security updates**:
   ```bash
   docker-compose pull
   docker-compose up -d
   ```

5. **Monitor logs and metrics**

### ğŸŒ Scaling and Load Balancing

For high-availability deployments:

```yaml
# docker-compose.prod.yml
services:
  cyber-assessment-reviewer:
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
```

### ğŸ”§ GPU Support

For NVIDIA GPU acceleration (Transformers mode):

1. **Install NVIDIA Container Toolkit**
2. **Uncomment GPU configuration** in docker-compose.yml
3. **Deploy with GPU support**:
   ```bash
   docker-compose -f docker-compose.transformers.yml up -d
   ```
